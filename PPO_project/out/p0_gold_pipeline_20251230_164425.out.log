[SEED] global seed set to 42 (random/numpy/torch)
加载配置: C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed42.yaml
environment:
  epsilon: 1.5
  interpolation_period: 0.001
  lookahead_points: 8
  max_steps: 4000
experiment:
  baseline_type: null
  category: p0_seed42
  enable_kcm: true
  mode: train
  model_path: null
  name: p0_seed42
  seed: 42
kinematic_constraints:
  MAX_ACC: 2000.0
  MAX_ANG_ACC: 100.0
  MAX_ANG_JERK: 1000.0
  MAX_ANG_VEL: 6.283185307179586
  MAX_JERK: 20000.0
  MAX_VEL: 100.0
path:
  closed: true
  num_points: 200
  scale: 10.0
  square: {}
  type: square
ppo:
  actor_lr: 2.0e-05
  batch_size: null
  critic_lr: 0.0001
  ent_coef: 0.01
  epochs: 10
  eps: 0.1
  gamma: 0.99
  hidden_dim: 256
  lmbda: 0.95
reward_weights:
  corridor:
    barrier_scale_ratio: 0.05
    barrier_weight: 2.0
    center_power: 1.0
    center_weight: 1.2
    dir_pref_beta: 2.0
    dir_pref_weight: 1.0
    dist_enter: 6.0
    dist_exit: 8.0
    enabled: false
    exit_center_ramp_steps: 60
    heading_weight: 2.0
    margin_ratio: 0.1
    outside_penalty_weight: 20.0
    safe_margin_ratio: 0.2
    theta_enter_deg: 12.0
    theta_exit_deg: 6.0
  p4:
    d_scale: null
    debug: false
    exit_boost_enabled: true
    exit_progress_mult: 1.35
    exit_speed_target_min: 0.95
    exit_window_sec: 0.25
    p7_2_k: 0.01
    speed_cap_enabled: false
    speed_cap_eps: 1e-12
    speed_cap_k: 4
    speed_cap_preview_points: 8
    speed_cap_s_max: 30.0
    speed_cap_s_min: 1.0
    speed_cap_use_wddot: true
    speed_cap_use_wdot: true
    speed_weight: 6.0
    stall_enabled: true
    stall_penalty: -8.0
    stall_progress_eps: 1e-4
    stall_steps: 300
    stall_v_eps: 0.05
    theta_max_deg: 90.0
    time_penalty: -0.01
    v_max: 1.0
    v_min: 0.35
  p6_1:
    a_ref_max_ratio: 0.5
    du_enabled: true
    du_mode: l1
    j_ref_enabled: true
    j_ref_max_ratio: 0.5
    v_target_mode: accel
    v_target_smoother_enabled: false
    v_target_tau: 0.1
    w_du: 0.01
  p7_3:
    kappa_dkappa_limit: null
    kappa_smoothing_beta: 0.25
    kappa_smoothing_enabled: false
    stall_cap_low: 0.25
    trace_ring_size: 200
  p8:
    ang_cap_min_ratio: 0.1
    corner_exit_e_release_ratio: 0.5
    corner_exit_hold_steps: 3
    corner_exit_psi_release_deg: 30.0
    corner_mode_ignore_geom_cap: false
    corner_off_dist_scale: 4.0
    corner_on_dist_scale: 2.0
    recovery_e_release_ratio: 0.5
    recovery_e_warn_ratio: 0.75
    recovery_vcap: 0.1
    straight_mode_ignore_geom_cap: false
    use_corner_exit_hysteresis: true
    use_recovery_cap: false
    use_vcap_rate_limit: true
    vcap_rate_down: 0.05
    vcap_rate_up: 0.1
  w_e: 5.0
  w_s: 20.0
  w_smooth: 0.05
  w_t: 1.0
  w_tau: 2.0
seed: 42
training:
  checkpoint_interval_steps: 2048
  log_interval: 50
  num_episodes: 1000
  save_interval: 100
  smoothing_factor: 0.9
  use_obs_normalizer: false

使用设备: cuda
使用参数化路径 square, 采样点数: 200
[ENV] Effective parameters (from YAML or defaults):
  dt (interpolation_period): 0.001
  MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
[RUN] seed=42 mode=train dt=0.001 gamma=0.990000 H_steps≈100.0 H_time≈0.1000
[RUN] kinematic_constraints: MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
环境创建成功: 状态维度36, 动作维度=2
[OBS] Env 返回 normalized obs（训练端禁用 StateNormalizer）
PPO智能体创建成功 模式: train
断点续训: 从 C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed42\P0_gold_20251230_034122\checkpoints\latest_checkpoint.pth 恢复，已完成 episode=999, global_step=918995, best_eval_reward=-932.78
续训起始回合(1000)已达到总回合数(1000)，不再继续。
[ENV] Effective parameters (from YAML or defaults):
  dt (interpolation_period): 0.001
  MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
[p0_eval] 1/50 done_reason=success progress_final=1.0000 steps=928 elapsed=9.2s
[p0_eval] 5/50 done_reason=success progress_final=1.0000 steps=922 elapsed=45.9s
[p0_eval] 10/50 done_reason=success progress_final=1.0000 steps=901 elapsed=93.5s
[p0_eval] 15/50 done_reason=success progress_final=1.0000 steps=929 elapsed=139.2s
[p0_eval] 20/50 done_reason=success progress_final=1.0000 steps=949 elapsed=183.9s
[p0_eval] 25/50 done_reason=success progress_final=1.0000 steps=902 elapsed=227.8s
[p0_eval] 30/50 done_reason=success progress_final=1.0000 steps=910 elapsed=274.8s
[p0_eval] 35/50 done_reason=success progress_final=1.0000 steps=880 elapsed=320.1s
[p0_eval] 40/50 done_reason=success progress_final=1.0000 steps=920 elapsed=366.7s
[p0_eval] 45/50 done_reason=success progress_final=1.0000 steps=959 elapsed=415.7s
[p0_eval] 50/50 done_reason=success progress_final=1.0000 steps=898 elapsed=465.0s
{
  "phase": "p0_eval",
  "passed": true,
  "episodes": 50,
  "model_path": "C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed42\\P0_gold_20251230_034122\\checkpoints\\best_model.pth",
  "deterministic": false,
  "seed_eval": 42,
  "episode_set": null,
  "success_rate": 1.0,
  "stall_rate": 0.0,
  "mean_progress_final": 1.0,
  "max_abs_contour_error": 0.06469480202631317,
  "has_non_finite": false,
  "thresholds": {
    "success_rate_ge": 0.8,
    "stall_rate_le": 0.05,
    "mean_progress_final_ge": 0.95,
    "max_abs_contour_error_le": 0.75
  },
  "half_epsilon": 0.75,
  "timestamp": "2025-12-30 16:52:19",
  "config_path": "C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\configs\\train_square_p0_seed42.yaml"
}
[SEED] global seed set to 43 (random/numpy/torch)
加载配置: C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed43.yaml
environment:
  epsilon: 1.5
  interpolation_period: 0.001
  lookahead_points: 8
  max_steps: 4000
experiment:
  baseline_type: null
  category: p0_seed43
  enable_kcm: true
  mode: train
  model_path: null
  name: p0_seed43
  seed: 43
kinematic_constraints:
  MAX_ACC: 2000.0
  MAX_ANG_ACC: 100.0
  MAX_ANG_JERK: 1000.0
  MAX_ANG_VEL: 6.283185307179586
  MAX_JERK: 20000.0
  MAX_VEL: 100.0
path:
  closed: true
  num_points: 200
  scale: 10.0
  square: {}
  type: square
ppo:
  actor_lr: 2.0e-05
  batch_size: null
  critic_lr: 0.0001
  ent_coef: 0.01
  epochs: 10
  eps: 0.1
  gamma: 0.99
  hidden_dim: 256
  lmbda: 0.95
reward_weights:
  corridor:
    barrier_scale_ratio: 0.05
    barrier_weight: 2.0
    center_power: 1.0
    center_weight: 1.2
    dir_pref_beta: 2.0
    dir_pref_weight: 1.0
    dist_enter: 6.0
    dist_exit: 8.0
    enabled: false
    exit_center_ramp_steps: 60
    heading_weight: 2.0
    margin_ratio: 0.1
    outside_penalty_weight: 20.0
    safe_margin_ratio: 0.2
    theta_enter_deg: 12.0
    theta_exit_deg: 6.0
  p4:
    d_scale: null
    debug: false
    exit_boost_enabled: true
    exit_progress_mult: 1.35
    exit_speed_target_min: 0.95
    exit_window_sec: 0.25
    p7_2_k: 0.01
    speed_cap_enabled: false
    speed_cap_eps: 1e-12
    speed_cap_k: 4
    speed_cap_preview_points: 8
    speed_cap_s_max: 30.0
    speed_cap_s_min: 1.0
    speed_cap_use_wddot: true
    speed_cap_use_wdot: true
    speed_weight: 6.0
    stall_enabled: true
    stall_penalty: -8.0
    stall_progress_eps: 1e-4
    stall_steps: 300
    stall_v_eps: 0.05
    theta_max_deg: 90.0
    time_penalty: -0.01
    v_max: 1.0
    v_min: 0.35
  p6_1:
    a_ref_max_ratio: 0.5
    du_enabled: true
    du_mode: l1
    j_ref_enabled: true
    j_ref_max_ratio: 0.5
    v_target_mode: accel
    v_target_smoother_enabled: false
    v_target_tau: 0.1
    w_du: 0.01
  p7_3:
    kappa_dkappa_limit: null
    kappa_smoothing_beta: 0.25
    kappa_smoothing_enabled: false
    stall_cap_low: 0.25
    trace_ring_size: 200
  p8:
    ang_cap_min_ratio: 0.1
    corner_exit_e_release_ratio: 0.5
    corner_exit_hold_steps: 3
    corner_exit_psi_release_deg: 30.0
    corner_mode_ignore_geom_cap: false
    corner_off_dist_scale: 4.0
    corner_on_dist_scale: 2.0
    recovery_e_release_ratio: 0.5
    recovery_e_warn_ratio: 0.75
    recovery_vcap: 0.1
    straight_mode_ignore_geom_cap: false
    use_corner_exit_hysteresis: true
    use_recovery_cap: false
    use_vcap_rate_limit: true
    vcap_rate_down: 0.05
    vcap_rate_up: 0.1
  w_e: 5.0
  w_s: 20.0
  w_smooth: 0.05
  w_t: 1.0
  w_tau: 2.0
seed: 43
training:
  checkpoint_interval_steps: 2048
  log_interval: 50
  num_episodes: 1000
  save_interval: 100
  smoothing_factor: 0.9
  use_obs_normalizer: false

使用设备: cuda
使用参数化路径 square, 采样点数: 200
[ENV] Effective parameters (from YAML or defaults):
  dt (interpolation_period): 0.001
  MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
[RUN] seed=43 mode=train dt=0.001 gamma=0.990000 H_steps≈100.0 H_time≈0.1000
[RUN] kinematic_constraints: MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
环境创建成功: 状态维度36, 动作维度=2
[OBS] Env 返回 normalized obs（训练端禁用 StateNormalizer）
PPO智能体创建成功 模式: train
断点续训: 从 C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122\checkpoints\latest_checkpoint.pth 恢复，已完成 episode=537, global_step=1400832, best_eval_reward=-389.68

开始训练 共1000个回合


================================================================================
Episode 550 - 论文指标摘要:
================================================================================
  RMSE Error:              0.084660
  Mean Jerk:               19853.613907
  Roughness Proxy:         680000.000000
  Mean Velocity:           11.9110
  Max Error:               0.167323
  Mean KCM Intervention:   0.845808
  Steps:                   3279
  Progress:                1.0000
  Total Reward:            -3808.76
================================================================================


================================================================================
Episode 600 - 论文指标摘要:
================================================================================
  RMSE Error:              0.000074
  Mean Jerk:               18943.404905
  Roughness Proxy:         345057.096481
  Mean Velocity:           0.6251
  Max Error:               0.000260
  Mean KCM Intervention:   0.950609
  Steps:                   300
  Progress:                0.0047
  Total Reward:            -329.05
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 650 - 论文指标摘要:
================================================================================
  RMSE Error:              0.040914
  Mean Jerk:               19945.828819
  Roughness Proxy:         120000.000000
  Mean Velocity:           9.7761
  Max Error:               0.067676
  Mean KCM Intervention:   0.940918
  Steps:                   1846
  Progress:                0.4533
  Total Reward:            -2053.65
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 700 - 论文指标摘要:
================================================================================
  RMSE Error:              0.064112
  Mean Jerk:               19890.685321
  Roughness Proxy:         207115.380764
  Mean Velocity:           16.2638
  Max Error:               0.122826
  Mean KCM Intervention:   0.869664
  Steps:                   2411
  Progress:                1.0000
  Total Reward:            -2734.18
================================================================================


================================================================================
Episode 750 - 论文指标摘要:
================================================================================
  RMSE Error:              0.086270
  Mean Jerk:               19859.649123
  Roughness Proxy:         680000.000000
  Mean Velocity:           12.4530
  Max Error:               0.184294
  Mean KCM Intervention:   0.837515
  Steps:                   3135
  Progress:                1.0000
  Total Reward:            -3649.05
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 800 - 论文指标摘要:
================================================================================
  RMSE Error:              0.090277
  Mean Jerk:               19930.141420
  Roughness Proxy:         173388.996124
  Mean Velocity:           15.7346
  Max Error:               0.159551
  Mean KCM Intervention:   0.838442
  Steps:                   2482
  Progress:                1.0000
  Total Reward:            -2903.97
================================================================================


================================================================================
Episode 850 - 论文指标摘要:
================================================================================
  RMSE Error:              0.067956
  Mean Jerk:               19828.360738
  Roughness Proxy:         454567.728043
  Mean Velocity:           13.8122
  Max Error:               0.140163
  Mean KCM Intervention:   0.843088
  Steps:                   2839
  Progress:                1.0000
  Total Reward:            -3232.55
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 900 - 论文指标摘要:
================================================================================
  RMSE Error:              0.086323
  Mean Jerk:               19912.376780
  Roughness Proxy:         300000.000000
  Mean Velocity:           14.2637
  Max Error:               0.159890
  Mean KCM Intervention:   0.851185
  Steps:                   2739
  Progress:                1.0000
  Total Reward:            -3188.31
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 950 - 论文指标摘要:
================================================================================
  RMSE Error:              0.073568
  Mean Jerk:               19819.318972
  Roughness Proxy:         520000.000000
  Mean Velocity:           13.6167
  Max Error:               0.139798
  Mean KCM Intervention:   0.832628
  Steps:                   2878
  Progress:                1.0000
  Total Reward:            -3297.41
================================================================================

写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'
写入 latest_trajectory.csv 失败，已跳过本回合: [WinError 5] 拒绝访问。: 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv.tmp' -> 'C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\logs\\latest_trajectory.csv'

================================================================================
Episode 1000 - 论文指标摘要:
================================================================================
  RMSE Error:              0.088041
  Mean Jerk:               19926.884892
  Roughness Proxy:         222020.401955
  Mean Velocity:           13.5655
  Max Error:               0.161748
  Mean KCM Intervention:   0.816086
  Steps:                   2886
  Progress:                1.0000
  Total Reward:            -3367.37
================================================================================


================================================================================
训练完成！实验目录 C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122
日志目录: C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122\logs
================================================================================


最终模型已保存: C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122\checkpoints\tracking_model_final.pth

可视化最终轨迹(ε=1.500)
跳过最终轨迹可视化（DISABLE_FINAL_PLOT=1）
[ENV] Effective parameters (from YAML or defaults):
  dt (interpolation_period): 0.001
  MAX_VEL=100.0, MAX_ACC=2000.0, MAX_JERK=20000.0, MAX_ANG_VEL=6.283185307179586, MAX_ANG_ACC=100.0, MAX_ANG_JERK=1000.0
[p0_eval] 1/50 done_reason=stall progress_final=0.5122 steps=2108 elapsed=50.3s
[p0_eval] 5/50 done_reason=success progress_final=1.0000 steps=2853 elapsed=307.2s
[p0_eval] 10/50 done_reason=success progress_final=1.0000 steps=2736 elapsed=682.2s
[p0_eval] 15/50 done_reason=success progress_final=1.0000 steps=2809 elapsed=952.7s
[p0_eval] 20/50 done_reason=success progress_final=1.0000 steps=3582 elapsed=1261.1s
[p0_eval] 25/50 done_reason=success progress_final=1.0000 steps=3600 elapsed=1690.3s
[p0_eval] 30/50 done_reason=stall progress_final=0.2404 steps=746 elapsed=1958.2s
[p0_eval] 35/50 done_reason=success progress_final=1.0000 steps=2928 elapsed=2291.8s
[p0_eval] 40/50 done_reason=success progress_final=1.0000 steps=3331 elapsed=2682.6s
[p0_eval] 45/50 done_reason=success progress_final=1.0000 steps=2918 elapsed=3037.4s
[p0_eval] 50/50 done_reason=success progress_final=1.0000 steps=3286 elapsed=3391.1s
{
  "phase": "p0_eval",
  "passed": false,
  "episodes": 50,
  "model_path": "C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\saved_models\\p0_seed43\\P0_gold_20251230_034122\\checkpoints\\best_model.pth",
  "deterministic": false,
  "seed_eval": 43,
  "episode_set": null,
  "success_rate": 0.72,
  "stall_rate": 0.28,
  "mean_progress_final": 0.8286575376262042,
  "max_abs_contour_error": 0.1740128056350915,
  "has_non_finite": false,
  "thresholds": {
    "success_rate_ge": 0.8,
    "stall_rate_le": 0.05,
    "mean_progress_final_ge": 0.95,
    "max_abs_contour_error_le": 0.75
  },
  "half_epsilon": 0.75,
  "timestamp": "2025-12-31 03:56:52",
  "config_path": "C:\\Users\\wumin\\Nutstore\\1\\DDPG的轨迹平滑\\基于强化学习的轨迹平滑\\PPO_project\\configs\\train_square_p0_seed43.yaml"
}
[run] D:\Anaconda\envs\PPO\python.exe C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\main.py --mode train --config C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed42.yaml --experiment_name p0_seed42 --experiment_dir C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed42\P0_gold_20251230_034122 --resume C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed42\P0_gold_20251230_034122\checkpoints\latest_checkpoint.pth
[run] D:\Anaconda\envs\PPO\python.exe C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\tools\acceptance_suite.py --phase p0_eval --config C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed42.yaml --model C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed42\P0_gold_20251230_034122\checkpoints\best_model.pth --episodes 50 --out C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\artifacts\p0_eval_seed42_P0_gold_20251230_034122 --seed 42
[run] D:\Anaconda\envs\PPO\python.exe C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\main.py --mode train --config C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed43.yaml --experiment_name p0_seed43 --experiment_dir C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122 --resume C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122\checkpoints\latest_checkpoint.pth
[run] D:\Anaconda\envs\PPO\python.exe C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\tools\acceptance_suite.py --phase p0_eval --config C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\configs\train_square_p0_seed43.yaml --model C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\saved_models\p0_seed43\P0_gold_20251230_034122\checkpoints\best_model.pth --episodes 50 --out C:\Users\wumin\Nutstore\1\DDPG的轨迹平滑\基于强化学习的轨迹平滑\PPO_project\artifacts\p0_eval_seed43_P0_gold_20251230_034122 --seed 43
