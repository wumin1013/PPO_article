### **指令：基于强化学习的CNC高速高精度运动规划系统优化**

**目标**：

1. **扩展场景**：实现直线（Line）、正方形（Square）、S形（S-shape）三种轨迹的训练支持。
2. **物理仿真**：将运动学约束调整为真实高速机床级别（高加速度、高捷度）。
3. **智能行为**：通过参数重构，激发出“直线极速进给、弯道自动内切（Corner Cutting）、快速出弯”的高级驾驶策略，并解决S形轨迹无法到达终点的问题。

------

#### **Part 1. 路径生成器升级 (Path Generator Upgrade)**

**目标文件**：`src/utils/path_generator.py`

1. **新增 `generate_line_path` 函数**：
   - **逻辑**：生成从原点 `(0, 0)` 出发的直线。
   - **参数**：`length` (长度), `num_points` (点数), `angle` (角度, 默认0)。
2. **新增 `generate_square_path` 函数**：
   - **逻辑**：生成从 `(0, 0)`（左下角）开始的逆时针正方形路径。
   - **参数**：`side_length` (边长), `num_points` (总点数)。
   - **注意**：确保点在四个边上均匀分布，且路径闭合（首尾相接）。
3. **重构 `get_path_by_name` 接口**：
   - **清理**：移除 `butterfly` (及其变体)、`lemniscate`、`u_shape`、`star` 等非核心路径。
   - **注册**：仅保留并注册 `'line'`, `'square'`, `'s_shape'`, `'s_shape_bspline'`。
   - **参数映射**：
     - `line` 映射 `scale` -> `length`。
     - `square` 映射 `scale` -> `side_length`。

------

#### **Part 2. 环境逻辑固化 (Environment Logic Hardening)**

**目标文件**：`src/environment/cnc_env.py`

1. **强制取消课程学习（No Random Start）**：
   - 在 `reset(self, random_start=False)` 方法中，**忽略**传入的 `random_start` 参数。
   - **强制设置**内部标志 `use_random_start = False`。
   - **目的**：确保 Agent 每次训练都必须从路径起点 `(0, 0)` 开始，完整走完全程，以学习全局速度规划。
2. **增强观测能力（Code Logic Check）**：
   - 确认 `observation_space` 的维度计算依赖于 `config` 中的 `lookahead_points`。
   - （无需修改代码逻辑，只需确保它能动态读取 `default.yaml` 中的新值即可）。

------

#### **Part 3. 配置文件重构 (Configuration Overhaul) —— \**核心步骤\****

**目标文件**：`configs/default.yaml`

请完全替换或修改以下关键参数，这是实现“自动内切”和“快速进给”的关键。

**1. 运动学约束 (Kinematic Constraints) - 模拟高速机床**

- **`MAX_VEL`**: **0.5** (m/s) —— *对应 30m/min 的高速进给。*
- **`MAX_ACC`**: **5.0** (m/s²) —— *高动态响应，允许极短时间内加减速。*
- **`MAX_JERK`**: **100.0** (m/s³) —— *极高的捷度限制，允许“弹射”出弯和瞬间变加速。*
- *其他角速度/角加速度参数可按比例维持现状或适当增大。*

**2. 环境设置 (Environment) - 提供内切空间与预判能力**

- **`epsilon`**: **1.5** (mm/m) —— *[关键] 大幅放宽误差带。允许 Agent 在 $\pm 0.75$ 的宽度内自由选择切弯路径，而非死板跟踪中心线。*
- **`lookahead_points`**: **20** —— *[关键] 将前瞻点数从 5 增加到 20。让 Agent 能提前 2-3 秒看到前方弯道，从而提前规划内切路线，避免急刹车。*
- **`max_steps`**: **4000** —— *防止 S 形长路径因步数耗尽而失败。*

**3. 奖励权重 (Reward Weights) - 引导激进策略**

- **`w_progress`**: **2.0** —— *[提高] 只要能往前走，就给大奖励。这是克服“S形走不完”的最强动力。*
- **`w_violation`**: **5.0** —— *[降低] 原值为 12.0。大幅降低出界惩罚，鼓励 Agent 在边缘试探，而不是因恐惧而停滞不前。*
- **`w_velocity`**: **1.0** —— *保持适中，在直线段提供加速动力。*
- **`w_kcm_penalty`**: **1.5** —— *[提高] 原值为 0.8。由于物理约束变宽了，需要更严厉的惩罚来迫使 Agent 学会驾驭这台“猛兽”，不违反物理限制。*
- **`w_e` (走廊缓冲惩罚)**: **0.5** —— *[降低] 减少在安全管道内偏离中心线的惩罚，鼓励 Agent 放心大胆地“切弯”。*

**4. 初始训练路径**

- **`path.type`**: **'line'** —— *建议先设为直线。*
- **策略**：先用直线训练模型学会“地板油”（满速跑），然后将模型作为 Checkpoint，加载后修改配置为 `'s_shape'` 继续训练过弯能力。

------

**指令结束。**