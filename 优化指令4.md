# 优化指令 04：奖励函数重构与走廊控制

## 背景
我们需要摒弃“最小化轮廓误差”的传统思路，转而采用“误差带约束下的速度最大化”策略，并兼顾加工表面质量。

## 任务
重构 `src/environment/reward.py` 并同步更新 `configs/default.yaml`。

## 执行要求
1.  **走廊奖励设计:**
    * **安全区 (< 0.8ε):** 奖励主要由速度主导 (Go Fast!)，忽略微小误差。
    * **缓冲警告区 (0.8ε ~ 1.0ε):** 施加惩罚，提示回归。
    * **违规区 (> ε):** 强惩罚 + Done。

2.  **平滑度与物理一致性:**
    * **动作平滑 (Action Smoothness):** 惩罚 $|a_t - a_{t-1}|$，防止在走廊内高频震荡（Chattering）。
    * **KCM 协作:** 惩罚 **KCM 干预量**。引导 Agent 学会“自我收敛”，输出符合物理极限的指令，而不是依赖 KCM 强制截断。

3.  **配置同步:** 在 `default.yaml` 中添加所有新权重的默认值（如 `w_action_smooth`, `w_kcm_penalty`），防止 KeyError。

## 自验证
构造对比测试：
Case A: 贴着中心线慢速跑 (Vel=0.5)。
Case B: 偏离中心线但仍在安全区，全速跑 (Vel=1.0)。
**断言:** Case B 的 Step Reward 必须显著高于 Case A。